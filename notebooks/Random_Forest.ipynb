{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest,f_classif, VarianceThreshold\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed/X_train', 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "\n",
    "with open('../data/processed/X_test', 'rb') as f:\n",
    "    X_test = pickle.load(f)\n",
    "\n",
    "with open('../data/processed/y_train', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "with open('../data/processed/y_test', 'rb') as f:\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['Census_ProcessorCoreCount',\n",
    "                 'Census_PrimaryDiskTotalCapacity',\n",
    "                 'Census_SystemVolumeTotalCapacity',\n",
    "                 'Census_TotalPhysicalRAM',\n",
    "                 'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n",
    "                 'Census_InternalPrimaryDisplayResolutionHorizontal',\n",
    "                 'Census_InternalPrimaryDisplayResolutionVertical',\n",
    "                 'Census_InternalBatteryNumberOfCharges']\n",
    "rank_columns = [col for col in X_train.columns if 'encoded' in col]\n",
    "numerical_columns = numerical_columns + rank_columns\n",
    "\n",
    "binary_columns = [col for col in X_train.columns.tolist() if X_train[col].nunique() <= 2 if X_train[col].dtypes != 'O']\n",
    "\n",
    "categorical_columns = X_train.select_dtypes('object').columns.tolist()\n",
    "cat_num_columns = [col for col in X_train.columns.tolist() if col not in numerical_columns\n",
    "              if col not in binary_columns if col not in categorical_columns]\n",
    "tot_columns = numerical_columns + binary_columns + categorical_columns + cat_num_columns\n",
    "len(tot_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(numerical_columns), len(binary_columns), len(categorical_columns), len(cat_num_columns), len(numerical_columns)+ len(binary_columns) + len(categorical_columns) + len(cat_num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.mean(), y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer()\n",
    "\n",
    "# Preprocessing for binary data\n",
    "binary_transformer = SimpleImputer()\n",
    "\n",
    "# Preprocessing for categorical data encoded as numerical ID's\n",
    "categorical_num_transformer = SimpleImputer()\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_columns),\n",
    "        ('bin', binary_transformer, binary_columns),\n",
    "        ('cat_num', categorical_num_transformer, cat_num_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "rf_clf = RandomForestClassifier(random_state = 42)\n",
    "VarThresh = VarianceThreshold()\n",
    "#selector = SelectKBest(f_classif)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('VarThresh', VarThresh),\n",
    "                              #('selector', selector),\n",
    "                              ('classifier', rf_clf)\n",
    "                             ])\n",
    "\n",
    "\n",
    "n_estimators = [500, 1000, 1500, 2000]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(2, 20, num = 10)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [3, 5, 7, 10, 15, 20, 25]\n",
    "min_samples_leaf = [2, 3, 5, 7, 10, 15, 20, 25]\n",
    "#bootstrap = [True, False]\n",
    "\n",
    "parameters = {#'selector__k': [50, 70, 90, 110, 130],\n",
    "              'preprocessor__num__strategy': ['mean', 'median', 'constant'],\n",
    "              'preprocessor__bin__strategy': ['most_frequent', 'constant'],\n",
    "              'preprocessor__cat_num__strategy': ['most_frequent', 'constant'],\n",
    "              'preprocessor__cat__imputer__strategy': ['most_frequent', 'constant'],\n",
    "              'classifier__n_estimators': n_estimators,\n",
    "              'classifier__max_features' : max_features,\n",
    "              'classifier__max_depth': max_depth,\n",
    "              'classifier__min_samples_split': min_samples_split,\n",
    "              'classifier__min_samples_leaf': min_samples_leaf,\n",
    "              #'classifier__bootstrap': bootstrap\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "search = RandomizedSearchCV(estimator=my_pipeline, \n",
    "                             param_distributions=parameters,\n",
    "                             n_iter = 10,\n",
    "                             cv=5,\n",
    "                             scoring = 'roc_auc',\n",
    "                             return_train_score=True,\n",
    "                             #n_jobs = -1,\n",
    "                             verbose=3)\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimized model\n",
    "opt_rf_clf = search.best_estimator_\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = opt_rf_clf.predict(X_train)\n",
    "y_pred_test = opt_rf_clf.predict(X_test)\n",
    "\n",
    "print('Train Set roc auc:', roc_auc_score(y_train, y_pred_train))\n",
    "print('Test Set roc auc:', roc_auc_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC_AUC\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "y_pred_proba_test = opt_rf_clf.predict_proba(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_proba_test[:,1])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1], [0,1], '--', color = 'black')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "lables = {'Negative': 0, 'Positive': 1} \n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(conf_matrix, \n",
    "            annot=True,\n",
    "            annot_kws={'size':28},\n",
    "            fmt=\"d\",\n",
    "            xticklabels=lables.keys(), \n",
    "            yticklabels=lables.keys(),\n",
    "            cmap=\"Blues\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot precision - recall curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba_test[:,1])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(recall, precision)\n",
    "plt.plot([0, 1], [0.5, 0.5], '--', color = 'black')\n",
    "plt.title('Precision-Recall Curve for Optimized Logistic Regression')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "numerical_transformer_rev = SimpleImputer(strategy=search.best_params_['preprocessor__num__strategy'])\n",
    "\n",
    "# Preprocessing for binary data\n",
    "binary_transformer_rev = SimpleImputer(strategy=search.best_params_['preprocessor__bin__strategy'])\n",
    "\n",
    "# Preprocessing for categorical data encoded as numerical ID's\n",
    "categorical_num_transformer_rev = SimpleImputer(strategy=search.best_params_['preprocessor__cat_num__strategy'])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer_rev = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy=search.best_params_['preprocessor__cat__imputer__strategy'])),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor_rev = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer_rev, numerical_columns),\n",
    "        ('bin', binary_transformer_rev, binary_columns),\n",
    "        ('cat_num', categorical_num_transformer_rev, cat_num_columns),\n",
    "        ('cat', categorical_transformer_rev, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "pipeline_rev = Pipeline(steps=[('preprocessor', preprocessor_rev),\n",
    "                              ('VarThresh', VarThresh)\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_values = preprocessor_rev.fit_transform(X_train)\n",
    "onehot_cat_columns = pipeline_rev.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names(input_features=categorical_columns)\n",
    "onehot = onehot_cat_columns.tolist() \n",
    "columns_tot = numerical_columns + binary_columns + cat_num_columns + onehot\n",
    "\n",
    "feature_importance = pd.Series(data=opt_rf_clf.named_steps['classifier'].feature_importances_, index = np.array(columns_tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Check for orders of feat imp and std, i might have switched them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,100))\n",
    "sns.barplot(y=feature_importance.index, \n",
    "            x=feature_importance.values, \n",
    "            orient='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importance = feature_importance.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std([tree.feature_importances_ for tree in opt_rf_clf.named_steps['classifier'].estimators_], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_df = pd.DataFrame(list(zip(feature_importance, std)), columns=['Importance', 'std'], index=feature_importance.index)\n",
    "imp_df_sorted = imp_df.sort_values(by='Importance', ascending=True).reset_index()\n",
    "imp_df_sorted.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(20,300))\n",
    "#sns.barplot(y='index', x='Importance', data = imp_df_sorted, orient='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imp_df_sorted.plot(kind='barh', y='Importance', x='index' , xerr='std', figsize=(20,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "opt_rf_clf_rev = opt_rf_clf\n",
    "train_sizes, train_scores, test_scores = learning_curve(opt_rf_clf_rev, \n",
    "                                                        X_train, \n",
    "                                                        y_train, \n",
    "                                                        cv=5, \n",
    "                                                        scoring='roc_auc',\n",
    "                                                        n_jobs=1,\n",
    "                                                        train_sizes=np.linspace(.01, 1.0, 5), \n",
    "                                                        verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                 color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'd-', color=\"r\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    \n",
    "plt.ylim(0.5, 1.01)\n",
    "   \n",
    "    \n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Training examples')\n",
    "plt.ylabel('ROC_AUC Score')\n",
    "plt.title('Learning Curve (Random Forest)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = [X_train, X_test]\n",
    "y_train_full= [y_train, y_test]\n",
    "\n",
    "X_train_full = pd.concat(X_train_full)\n",
    "y_train_full = pd.concat(y_train_full)\n",
    "\n",
    "X_train_full.shape, y_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_rf_clf.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/optimized_RF.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(opt_rf_clf, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
