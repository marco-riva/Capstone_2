{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71371, 65)\n",
      "(17843, 65)\n",
      "(71371,)\n",
      "(17843,)\n"
     ]
    }
   ],
   "source": [
    "with open('../data/processed/X_train', 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "\n",
    "with open('../data/processed/X_test', 'rb') as f:\n",
    "    X_test = pickle.load(f)\n",
    "\n",
    "with open('../data/processed/y_train', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "with open('../data/processed/y_test', 'rb') as f:\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_columns = ['Census_ProcessorCoreCount',\n",
    "                 'Census_PrimaryDiskTotalCapacity',\n",
    "                 'Census_SystemVolumeTotalCapacity',\n",
    "                 'Census_TotalPhysicalRAM',\n",
    "                 'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n",
    "                 'Census_InternalPrimaryDisplayResolutionHorizontal',\n",
    "                 'Census_InternalPrimaryDisplayResolutionVertical',\n",
    "                 'Census_InternalBatteryNumberOfCharges']\n",
    "rank_columns = [col for col in X_train.columns if 'encoded' in col]\n",
    "numerical_columns = numerical_columns + rank_columns\n",
    "\n",
    "binary_columns = [col for col in X_train.columns.tolist() if X_train[col].nunique() <= 2 if X_train[col].dtypes != 'O']\n",
    "\n",
    "categorical_columns = X_train.select_dtypes('object').columns.tolist()\n",
    "cat_num_columns = [col for col in X_train.columns.tolist() if col not in numerical_columns\n",
    "              if col not in binary_columns if col not in categorical_columns]\n",
    "tot_columns = numerical_columns + binary_columns + categorical_columns + cat_num_columns\n",
    "len(tot_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 9, 17, 7, 65)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numerical_columns), len(binary_columns), len(categorical_columns), len(cat_num_columns), len(numerical_columns)+ len(binary_columns) + len(categorical_columns) + len(cat_num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5005114121982318, 0.5026621083898447)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean(), y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer()\n",
    "\n",
    "# Preprocessing for binary data\n",
    "binary_transformer = SimpleImputer()\n",
    "\n",
    "# Preprocessing for categorical data encoded as numerical ID's\n",
    "categorical_num_transformer = SimpleImputer()\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_columns),\n",
    "        ('bin', binary_transformer, binary_columns),\n",
    "        ('cat_num', categorical_num_transformer, cat_num_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-c183b56ef377>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-c183b56ef377>\"\u001b[1;36m, line \u001b[1;32m21\u001b[0m\n\u001b[1;33m    'classifier__learning_rate': [0.05 0.1, 0.3, 0.05],\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "xgb_clf = xgb.XGBClassifier(objective = 'binary:logistic', \n",
    "                            eval_metric='logloss', \n",
    "                            use_label_encoder =False,\n",
    "                            verbosity=0)\n",
    "VarThresh = VarianceThreshold()\n",
    "#selector = SelectKBest(f_classif)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('VarThresh', VarThresh),\n",
    "                            #('selector', selector),\n",
    "                            ('classifier', xgb_clf)\n",
    "                            ])\n",
    "\n",
    "\n",
    "parameters = {'preprocessor__num__strategy': ['mean', 'median', 'constant'],\n",
    "              'preprocessor__bin__strategy': ['most_frequent', 'constant'],\n",
    "              'preprocessor__cat_num__strategy': ['most_frequent', 'constant'],\n",
    "              'preprocessor__cat__imputer__strategy': ['most_frequent', 'constant'],\n",
    "              'classifier__learning_rate': [0.05 0.1, 0.3, 0.05],\n",
    "              'classifier__gamma' : [0, 0.01, 0.1],\n",
    "              'classifier__max_depth': range(2, 20, 2),\n",
    "              'classifier__colsample_bytree': [0.3, 0.6, 0.8, 1.0],\n",
    "              'classifier__subsample': [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "              'classifier__reg_alpha': [0, 0.5, 1, 1.5],\n",
    "              'classifier__reg_lambda': [0, 0.5, 1, 1.5],\n",
    "              'classifier__min_child_weight': [1, 3, 5, 7],\n",
    "              'classifier__n_estimators': [500, 1000, 1500, 2000, 2500]}\n",
    "\n",
    "\n",
    "# Grid search\n",
    "search = RandomizedSearchCV(estimator=pipeline, \n",
    "                             param_distributions=parameters,\n",
    "                             n_iter = 15,\n",
    "                             cv=5,\n",
    "                             scoring = 'roc_auc',\n",
    "                             return_train_score=True,\n",
    "                             #n_jobs = -1,\n",
    "                             verbose=3)\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized model\n",
    "opt_xgb_clf = search.best_estimator_\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = opt_xgb_clf.predict(X_train)\n",
    "y_pred_test = opt_xgb_clf.predict(X_test)\n",
    "\n",
    "print('Train Set roc auc:', roc_auc_score(y_train, y_pred_train))\n",
    "print('Test Set roc auc:', roc_auc_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC_AUC\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "y_pred_proba_test = opt_xgb_clf.predict_proba(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_proba_test[:,1])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1], [0,1], '--', color = 'black')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "lables = {'Negative': 0, 'Positive': 1} \n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(conf_matrix, \n",
    "            annot=True,\n",
    "            annot_kws={'size':28},\n",
    "            fmt=\"d\",\n",
    "            xticklabels=lables.keys(), \n",
    "            yticklabels=lables.keys(),\n",
    "            cmap=\"Blues\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot precision - recall curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba_test[:,1])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(recall, precision)\n",
    "plt.plot([0, 1], [0.5, 0.5], '--', color = 'black')\n",
    "plt.title('Precision-Recall Curve for Optimized Logistic Regression')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "numerical_transformer_rev = SimpleImputer(strategy=search.best_params_['preprocessor__num__strategy'])\n",
    "\n",
    "# Preprocessing for binary data\n",
    "binary_transformer_rev = SimpleImputer(strategy=search.best_params_['preprocessor__bin__strategy'])\n",
    "\n",
    "# Preprocessing for categorical data encoded as numerical ID's\n",
    "categorical_num_transformer_rev = SimpleImputer(strategy=search.best_params_['preprocessor__cat_num__strategy'])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer_rev = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy=search.best_params_['preprocessor__cat__imputer__strategy'])),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor_rev = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer_rev, numerical_columns),\n",
    "        ('bin', binary_transformer_rev, binary_columns),\n",
    "        ('cat_num', categorical_num_transformer_rev, cat_num_columns),\n",
    "        ('cat', categorical_transformer_rev, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "pipeline_rev = Pipeline(steps=[('preprocessor', preprocessor_rev),\n",
    "                              ('VarThresh', VarThresh)\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_values = preprocessor_rev.fit_transform(X_train)\n",
    "onehot_cat_columns = pipeline_rev.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names(input_features=categorical_columns)\n",
    "onehot = onehot_cat_columns.tolist() \n",
    "columns_tot = numerical_columns + binary_columns + cat_num_columns + onehot\n",
    "\n",
    "feature_importance = pd.Series(data=opt_xgb_clf.named_steps['classifier'].feature_importances_, index = np.array(columns_tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importance = feature_importance.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,100))\n",
    "sns.barplot(y=feature_importance.index, \n",
    "            x=feature_importance.values, \n",
    "            orient='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "opt_xgb_clf_rev = opt_xgb_clf\n",
    "train_sizes, train_scores, test_scores = learning_curve(opt_xgb_clf_rev, \n",
    "                                                        X_train, \n",
    "                                                        y_train, \n",
    "                                                        cv=5, \n",
    "                                                        scoring='roc_auc',\n",
    "                                                        n_jobs=1,\n",
    "                                                        train_sizes=np.linspace(.01, 1.0, 5), \n",
    "                                                        verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                 color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'd-', color=\"r\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    \n",
    "plt.ylim(0.5, 1.01)\n",
    "   \n",
    "    \n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Training examples')\n",
    "plt.ylabel('ROC_AUC Score')\n",
    "plt.title('Learning Curve (XGB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = [X_train, X_test]\n",
    "y_train_full= [y_train, y_test]\n",
    "\n",
    "X_train_full = pd.concat(X_train_full)\n",
    "y_train_full = pd.concat(y_train_full)\n",
    "\n",
    "X_train_full.shape, y_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_xgb_clf.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(opt_xgb_clf, open(\"../models/optimized_XGB.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
